{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import argparse\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "\n",
    "from chainer.datasets import tuple_dataset\n",
    "from chainer.dataset import convert, concat_examples\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import easy_chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class MLP(chainer.Chain):\n",
    "#    def __init__(self, n_units, n_out):\n",
    "#       super(MLP, self).__init__()\n",
    "#        with self.init_scope():\n",
    "#            # the size of the inputs to each layer will be inferred\n",
    "#           self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "#            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "#            self.l3 = L.Linear(None, n_out)    # n_units -> n_out\n",
    "\n",
    "#    def __call__(self, x):\n",
    "#        h1 = F.relu(self.l1(x))\n",
    "#        h2 = F.relu(self.l2(h1))\n",
    "#        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import glob\n",
    "#import numpy\n",
    "\n",
    "\n",
    "\n",
    "#co_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/cotton-*\"))\n",
    "#sl_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/silk-*\"))\n",
    "#li_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/linen-*\"))\n",
    "#po_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/poly-*\"))\n",
    "#ac_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/acrylic-*\"))\n",
    "#ny_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/nylon-*\"))\n",
    "#pp_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/pp-*\"))\n",
    "#ra_list = sorted(glob.glob(\"/home/fiber_classifier/Desktop/oono/rayon-*\"))\n",
    "\n",
    "\n",
    "#for i, fname in enumerate(ny_list):\n",
    "#     print(r\"%d: %s\" % (i, fname))\n",
    "#    xls = pandas.read_csv(fname, skiprows=4, delimiter=\"\\t\", header=None)\n",
    "#    name = os.path.split(fname)[1].split(\".\")[0] # add:: 2018.07.23\n",
    "\n",
    " #   if i == 0:       \n",
    "#        arr = xls.as_matrix()[:,1]  # numpy.array\n",
    "#        hddr = name # add:: 2018.07.23\n",
    "#    else:\n",
    "#        arr = numpy.vstack((arr, xls.as_matrix()[:,1]))\n",
    "#        hddr = numpy.hstack((hddr, name)) # add:: 2018.07.23\n",
    "\n",
    "#print(arr.shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "wo_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/wool-*\"))\n",
    "cs_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/cashmire-*\"))\n",
    "ca_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/camel-*\"))\n",
    "go_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/goat-*\"))\n",
    "ib_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/ibex-*\"))\n",
    "ya_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/animal/yak-*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Owner/Desktop/animal\\\\wool-1.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-10.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-2.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-3.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-4.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-5.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-6.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-7.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-8.txt',\n",
       " 'C:/Users/Owner/Desktop/animal\\\\wool-9.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0a5a88dbbdc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# col = numpy.arange(1713)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwo_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# col = numpy.arange(1713)\n",
    "xls = pandas.read_csv(wo_list[0], skiprows=4, delimiter=\"\\t\", header=None)\n",
    "col = xls.as_matrix()[:,0]\n",
    "\n",
    "j = 0\n",
    "for list_ in (wo_list, cs_list, ca_list, go_list, ib_list, ya_list):\n",
    "#     print(list_)\n",
    "    for i, fname in enumerate (list_):\n",
    "        xls = pandas.read_csv(fname, comment=\"#\", delimiter=\"\\t\", header=None)\n",
    "        if j == 0:\n",
    "            arr = xls.as_matrix()[:,1]\n",
    "            hddr = os.path.split(fname)[1].split(\".\")[0]\n",
    "        else:\n",
    "            arr = numpy.vstack((arr, xls.as_matrix()[:,1]))\n",
    "            hddr = numpy.hstack((hddr, os.path.split(fname)[1].split(\".\")[0]))\n",
    "        j += 1\n",
    "#arr = numpy.random.random((10,2526))  # \n",
    "#hddr = numpy.array([\"test%s\" % v for v in range(10)])\n",
    "\n",
    "#ref = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2385) (2385,) (60,)\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape, col.shape, hddr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(data=arr.T,  # spectra, reference\n",
    "                      index=col,  # wavenumber\n",
    "                      columns=hddr)  # file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"C:/Users/Owner/Desktop/animal/animal_6class.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easy_chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.\n",
      "  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.  4.  5.\n",
      "  5.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.\n",
      "  7.  7.  8.  8.  8.  8.  8.  8.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10.\n",
      " 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 11. 11.  0.  0.  0.  1.  1.  1.\n",
      "  2.  2.  2.  3.  3.  3.  4.  4.  4.  5.  5.  5.  6.  6.  6.  7.  7.  7.\n",
      "  8.  8.  8.  9.  9.  9. 10. 10. 10. 11. 11. 11.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Desktop\\LAB\\LAB 2018\\jupyter File\\easy_chainer.py:87: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = xls.as_matrix()[:-1]\n",
      "C:\\Users\\Owner\\Desktop\\LAB\\LAB 2018\\jupyter File\\easy_chainer.py:88: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  teach = xls.as_matrix()[-1]\n"
     ]
    }
   ],
   "source": [
    "data, teach = easy_chainer.load_Data(\"C:/Users/Owner/Desktop/LAB/LAB 2019/解析/前処理/1_11/1_11_2.xlsx\")\n",
    "data = data.astype(numpy.float32)\n",
    "teach = teach \n",
    "print(teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=int64),\n",
       " array([ 0.        ,  0.91666667,  1.83333333,  2.75      ,  3.66666667,\n",
       "         4.58333333,  5.5       ,  6.41666667,  7.33333333,  8.25      ,\n",
       "         9.16666667, 10.08333333, 11.        ]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teach = teach.astype(numpy.int8)\n",
    "teach_bins = numpy.histogram(teach, bins=numpy.max(teach) + 1)\n",
    "teach_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "\n",
    "\n",
    "for i in range(int(max(teach) + 1)):\n",
    "    tmp0_arr = numpy.where(teach == i)[0]\n",
    "    try:\n",
    "        tmp0 = numpy.random.choice(tmp0_arr, int(k), replace=False)\n",
    "        if i == 0:\n",
    "            id_train = tmp0\n",
    "        else:\n",
    "            id_train = numpy.hstack((id_train, tmp0))\n",
    "    except Exception:\n",
    "        print(\"Not teach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_train = id_train.astype(numpy.float32)\n",
    "teach = teach.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   4   7  11  15  17  18  24  26  31  32  34  38  40  43  46  55  61\n",
      "  64  70  74  76  78  81  84  89  93 101 102 105 106 108 110 111 113 119]\n"
     ]
    }
   ],
   "source": [
    "id_all = numpy.arange(1, len(teach) + 1, 1).astype(numpy.int32) - 1\n",
    "# print(id_all)\n",
    "id_test = numpy.delete(id_all, id_train)\n",
    "print(id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data[:, id_train], teach[id_train]\n",
    "x_test, y_test = data[:, id_test], teach[id_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tuple_dataset.TupleDataset(x_train.T, y_train.reshape(-1, ))\n",
    "test = tuple_dataset.TupleDataset(x_test.T, y_test.reshape(-1, ))\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, 84)\n",
    "test_iter = chainer.iterators.SerialIterator(test, 36, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "            self.l2 = L.Linear(None, n_units)  # n_units -> n_units\n",
    "            self.l3 = L.Linear(None, n_out)  # n_units -> n_out\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L.Classifier(predictor=MLP(1000,12),\n",
    "                     lossfun=F.softmax_cross_entropy,\n",
    "                    accfun=F.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = chainer.optimizers.Adam()\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "updater = training.updaters.StandardUpdater(\n",
    "        train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (100, 'epoch'), out=\"Result2018_oono/%s\" % time.strftime(\"%Y%m%d%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "21          1.80905     1.755                 0.27381        0.333333                  0.146329      \n",
      "22          1.77033     1.71408               0.309524       0.333333                  0.510307      \n",
      "23          1.73199     1.67495               0.321429       0.361111                  0.926641      \n",
      "24          1.69603     1.63614               0.357143       0.416667                  1.3801        \n",
      "25          1.66083     1.59755               0.416667       0.416667                  1.76614       \n",
      "26          1.62607     1.56013               0.428571       0.444444                  2.14963       \n",
      "27          1.59246     1.52405               0.452381       0.5                       2.52096       \n",
      "28          1.56012     1.48887               0.440476       0.5                       2.91041       \n",
      "29          1.5285      1.45432               0.428571       0.5                       3.29708       \n",
      "30          1.49752     1.42092               0.440476       0.472222                  3.67885       \n",
      "31          1.46786     1.38828               0.464286       0.5                       4.19502       \n",
      "32          1.43878     1.35675               0.488095       0.5                       4.59862       \n",
      "33          1.41063     1.32675               0.488095       0.5                       4.99058       \n",
      "34          1.38401     1.29743               0.488095       0.527778                  5.34912       \n",
      "35          1.35809     1.26937               0.488095       0.5                       5.71532       \n",
      "36          1.33344     1.24223               0.5            0.527778                  6.08822       \n",
      "37          1.30975     1.21567               0.52381        0.555556                  6.50435       \n",
      "38          1.28688     1.19023               0.5            0.555556                  6.93115       \n",
      "39          1.2651      1.16547               0.52381        0.583333                  7.37785       \n",
      "40          1.24401     1.14276               0.535714       0.583333                  7.77646       \n",
      "41          1.22402     1.12101               0.535714       0.611111                  8.16808       \n",
      "42          1.20459     1.1                   0.583333       0.666667                  8.56527       \n",
      "43          1.18601     1.07869               0.547619       0.666667                  8.94073       \n",
      "44          1.16804     1.06006               0.571429       0.611111                  9.31905       \n",
      "45          1.15078     1.04124               0.571429       0.638889                  9.6919        \n",
      "46          1.13403     1.02361               0.559524       0.666667                  10.0837       \n",
      "47          1.11778     1.00582               0.571429       0.666667                  10.5701       \n",
      "48          1.10218     0.98987               0.559524       0.694444                  10.9681       \n",
      "49          1.08707     0.974847              0.595238       0.694444                  11.3281       \n",
      "50          1.07257     0.959766              0.547619       0.638889                  11.6931       \n",
      "51          1.05845     0.946405              0.595238       0.75                      12.0825       \n",
      "52          1.04451     0.932273              0.619048       0.694444                  12.448        \n",
      "53          1.03114     0.921534              0.607143       0.694444                  12.8141       \n",
      "54          1.01827     0.908837              0.571429       0.666667                  13.268        \n",
      "55          1.00539     0.895734              0.642857       0.638889                  13.6971       \n",
      "56          0.993366    0.886703              0.642857       0.722222                  14.0944       \n",
      "57          0.9816      0.877458              0.642857       0.666667                  14.467        \n",
      "58          0.970298    0.866017              0.583333       0.694444                  14.8828       \n",
      "59          0.959239    0.856405              0.654762       0.694444                  15.3387       \n",
      "60          0.948141    0.848924              0.630952       0.694444                  15.727        \n",
      "61          0.937671    0.839144              0.642857       0.638889                  16.1101       \n",
      "62          0.927914    0.831969              0.654762       0.75                      16.5584       \n",
      "63          0.917776    0.823715              0.630952       0.75                      16.9402       \n",
      "64          0.908774    0.817507              0.619048       0.694444                  17.2961       \n",
      "65          0.900734    0.811259              0.666667       0.75                      17.6563       \n",
      "66          0.891233    0.803669              0.642857       0.75                      18.058        \n",
      "67          0.881984    0.794446              0.678571       0.666667                  18.4333       \n",
      "68          0.874662    0.792271              0.654762       0.75                      18.7964       \n",
      "69          0.865261    0.786979              0.642857       0.75                      19.1624       \n",
      "70          0.857422    0.781196              0.690476       0.666667                  19.5974       \n",
      "71          0.850152    0.7747                0.678571       0.694444                  19.9696       \n",
      "72          0.84108     0.771625              0.642857       0.777778                  20.3403       \n",
      "73          0.834246    0.766247              0.666667       0.666667                  20.8219       \n",
      "74          0.827445    0.764839              0.642857       0.722222                  21.1953       \n",
      "75          0.819665    0.759778              0.654762       0.777778                  21.5607       \n",
      "76          0.81213     0.749751              0.702381       0.694444                  21.9833       \n",
      "77          0.80412     0.749333              0.666667       0.722222                  22.3901       \n",
      "78          0.796862    0.74466               0.690476       0.75                      22.7914       \n",
      "79          0.789687    0.737367              0.702381       0.694444                  23.1973       \n",
      "80          0.781982    0.738207              0.690476       0.722222                  23.5849       \n",
      "81          0.775325    0.731055              0.702381       0.75                      23.9633       \n",
      "82          0.767985    0.724991              0.72619        0.75                      24.3549       \n",
      "83          0.760155    0.724228              0.702381       0.722222                  24.7291       \n",
      "84          0.753537    0.722306              0.72619        0.75                      25.1166       \n",
      "85          0.74589     0.715932              0.738095       0.75                      25.5877       \n",
      "86          0.738474    0.710765              0.738095       0.75                      25.993        \n",
      "87          0.732201    0.71198               0.738095       0.75                      26.3655       \n",
      "88          0.724419    0.703627              0.75           0.75                      26.7564       \n",
      "89          0.717356    0.705517              0.75           0.666667                  27.1421       \n",
      "90          0.710987    0.697987              0.761905       0.75                      27.6756       \n",
      "91          0.70334     0.700313              0.785714       0.722222                  28.0693       \n",
      "92          0.696908    0.69046               0.809524       0.777778                  28.5032       \n",
      "93          0.690107    0.691621              0.797619       0.777778                  28.9165       \n",
      "94          0.682046    0.684432              0.797619       0.75                      29.3026       \n",
      "95          0.675042    0.683705              0.809524       0.722222                  29.7184       \n",
      "96          0.667839    0.679828              0.785714       0.777778                  30.1178       \n",
      "97          0.660717    0.672253              0.821429       0.777778                  30.5125       \n",
      "98          0.653919    0.674013              0.821429       0.75                      30.9375       \n",
      "99          0.647137    0.66521               0.821429       0.777778                  31.3608       \n",
      "100         0.640585    0.668644              0.797619       0.777778                  31.8151       \n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "# Take a snapshot for each specified epoch\n",
    "# frequency = args.epoch if args.frequency == -1 else max(1, args.frequency)\n",
    "# trainer.extend(extensions.snapshot(), trigger=(frequency, 'epoch'))\n",
    "\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport())\n",
    "\n",
    "# Save two plot images to the result dir\n",
    "trainer.extend(\n",
    "    extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
    "                          'epoch', file_name='loss.png'))\n",
    "trainer.extend(\n",
    "    extensions.PlotReport(\n",
    "        ['main/accuracy', 'validation/main/accuracy'],\n",
    "        'epoch', file_name='accuracy.png'))\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'main/loss', 'validation/main/loss',\n",
    "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "\n",
    "# Print a progress bar to stdout\n",
    "trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "# if args.resume:\n",
    "#     # Resume from a snapshot\n",
    "#     chainer.serializers.load_npz(args.resume, trainer)\n",
    "\n",
    "# Run the training\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref: 0, Pred: 6 False\n",
      "Ref: 0, Pred: 6 False\n",
      "Ref: 1, Pred: 11 False\n",
      "Ref: 1, Pred: 7 False\n",
      "Ref: 2, Pred: 12 False\n",
      "Ref: 2, Pred: 11 False\n",
      "Ref: 2, Pred: 7 False\n",
      "Ref: 3, Pred: 8 False\n",
      "Ref: 3, Pred: 12 False\n",
      "Ref: 4, Pred: 6 False\n",
      "Ref: 4, Pred: 4 True\n",
      "Ref: 4, Pred: 10 False\n",
      "Ref: 5, Pred: 4 False\n",
      "Ref: 5, Pred: 0 False\n",
      "Ref: 6, Pred: 0 False\n",
      "Ref: 6, Pred: 11 False\n",
      "Ref: 7, Pred: 5 False\n",
      "Ref: 8, Pred: 13 False\n",
      "Ref: 9, Pred: 8 False\n",
      "Ref: 10, Pred: 6 False\n",
      "Ref: 10, Pred: 4 False\n",
      "Ref: 10, Pred: 10 True\n",
      "Ref: 11, Pred: 8 False\n",
      "Ref: 11, Pred: 4 False\n",
      "Ref: 0, Pred: 8 False\n",
      "Ref: 1, Pred: 3 False\n",
      "Ref: 3, Pred: 2 False\n",
      "Ref: 5, Pred: 3 False\n",
      "Ref: 6, Pred: 6 True\n",
      "Ref: 7, Pred: 2 False\n",
      "Ref: 7, Pred: 8 False\n",
      "Ref: 8, Pred: 12 False\n",
      "Ref: 8, Pred: 0 False\n",
      "Ref: 9, Pred: 4 False\n",
      "Ref: 9, Pred: 8 False\n",
      "Ref: 11, Pred: 6 False\n"
     ]
    }
   ],
   "source": [
    "test_iter.reset()\n",
    "\n",
    "test_batch = test_iter.next()\n",
    "test_spc, test_ref = concat_examples(test_batch)  # Test Dataset\n",
    "for i in range(36):\n",
    "    ref = test_ref[i]\n",
    "    pred = numpy.argmax(MLP(1000,14)(test_spc[i].reshape(1, -1)).data)\n",
    "    print(\"Ref: %d, Pred: %d %s\" % (ref, pred, ref == pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1afbfbf1fdce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_cpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m chainer.serializers.save_hdf5(\"./Result2018_oono/%s/model.hdf5\" % time.strftime(\"%Y%m%d_%H%M%S\"),\n\u001b[0;32m      4\u001b[0m                               obj=model)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.to_cpu()\n",
    "\n",
    "chainer.serializers.save_hdf5(\"./Result2018_oono/%s/model.hdf5\" % time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "                              obj=model)\n",
    "\n",
    "numpy.save(arr=id_test, file=\"./Result2018_oono/%s/test_id.npy\" % time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "numpy.save(arr=id_train, file=\"./Result2018_oono/%s/train_id.npy\"  % time.strftime(\"%Y%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
