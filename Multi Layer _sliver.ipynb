{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import argparse\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "\n",
    "from chainer.datasets import tuple_dataset\n",
    "from chainer.dataset import convert, concat_examples\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(chainer.Chain):\n",
    "    def __init__(self, n_units, n_out):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            # the size of the inputs to each layer will be inferred\n",
    "            self.l1 = L.Linear(None, n_units)  # n_in -> n_units\n",
    "            self.l2 = L.Linear(None, n_units)# n_units -> n_out\n",
    "            self.l3 = L.Linear(None, n_out)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation of dataset\n",
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2385)\n"
     ]
    }
   ],
   "source": [
    "co_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/cotton-*\"))\n",
    "sl_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/silk-*\"))\n",
    "li_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/linen-*\"))\n",
    "wo_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/wool-*\"))\n",
    "ac_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/acrylic-*\"))\n",
    "ny_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/nylon-*\"))\n",
    "ra_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/rayon-*\"))\n",
    "po_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/poly-*\"))\n",
    "pp_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/train_data/2018.07.10/pp-*\"))\n",
    "\n",
    "tco_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/cotton-*\"))\n",
    "tsl_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/silk-*\"))\n",
    "tli_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/linen-*\"))\n",
    "two_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/wool-*\"))\n",
    "tac_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/acrylic-*\"))\n",
    "tny_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/nylon-*\"))\n",
    "tra_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/rayon-*\"))\n",
    "tpo_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/poly-*\"))\n",
    "tpp_list = sorted(glob.glob(\"C:/Users/Owner/Desktop/NN_project/test_data/2018.07.10/pp-*\"))\n",
    "\n",
    "\n",
    "for i, fname in enumerate(co_list):\n",
    "#     print(r\"%d: %s\" % (i, fname))\n",
    "    xls = pandas.read_csv(fname, skiprows=4, delimiter=\"\\t\", header=None)\n",
    "    name = os.path.split(fname)[1].split(\".\")[0] # add:: 2018.07.23\n",
    "\n",
    "    if i == 0:       \n",
    "        arr = xls.as_matrix()[:,1]  # numpy.array\n",
    "        hddr = name # add:: 2018.07.23\n",
    "    else:\n",
    "        arr = numpy.vstack((arr, xls.as_matrix()[:,1]))\n",
    "        hddr = numpy.hstack((hddr, name)) # add:: 2018.07.23\n",
    "\n",
    "print(arr.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "f = pandas.read_excel(\"C:/Users/Owner/Desktop/blood_glucose.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = f[:].T\n",
    "arr = arr.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1001)\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-5c7620bb3bc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "label = f[1000:].T\n",
    "label = label.astype(numpy.int32)\n",
    "print(label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 4 4 4 4 4 4 0 0 1 1 2 2 3 3 4 4]\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "label = numpy.hstack((numpy.zeros(7), numpy.ones(9), numpy.ones(14)*2, numpy.ones(14)*3, numpy.ones(6)*4,\n",
    "                    numpy.zeros(2), numpy.ones(2), numpy.ones(2)*2, numpy.ones(2)*3, numpy.ones(2)*4)).astype(numpy.int32)\n",
    "print(label)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 2385)\n",
      "(21, 2385)\n",
      "(28, 2385)\n",
      "(35, 2385)\n",
      "(42, 2385)\n",
      "(49, 2385)\n",
      "(56, 2385)\n",
      "(63, 2385)\n",
      "(66, 2385)\n",
      "(69, 2385)\n",
      "(72, 2385)\n",
      "(75, 2385)\n",
      "(78, 2385)\n",
      "(81, 2385)\n",
      "(84, 2385)\n",
      "(87, 2385)\n",
      "(90, 2385)\n"
     ]
    }
   ],
   "source": [
    "for list_ in (sl_list, li_list, wo_list, ac_list, ny_list, ra_list, pp_list,po_list, \n",
    "              tco_list, tsl_list, tli_list, two_list, tac_list, tny_list, tra_list, tpp_list, tpo_list):\n",
    "    for i, fname in enumerate(list_):\n",
    "        xls = pandas.read_csv(fname, skiprows=4, delimiter=\"\\t\", header=None)\n",
    "        arr = numpy.vstack((arr, xls.as_matrix()[:,1]))\n",
    "        hddr = numpy.hstack((hddr, os.path.split(fname)[1].split(\".\")[0])) # add:: 2018.07.23\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "label = numpy.hstack((numpy.zeros(7), numpy.ones(7), numpy.ones(7)*2, numpy.ones(7)*3, numpy.ones(7)*4, \n",
    "                      numpy.ones(7)*5, numpy.ones(7)*6, numpy.ones(7)*7, numpy.ones(7)*8,\n",
    "                      numpy.zeros(3),numpy.ones(3)*1, numpy.ones(3)*2, \n",
    "                      numpy.ones(3)*3,numpy.ones(3)*4, \n",
    "                      numpy.ones(3)*5, numpy.ones(3)*6, numpy.ones(3)*7, numpy.ones(3)*8)).astype(numpy.int32)\n",
    "print(label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 0, 0, 0,\n",
       "       1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8,\n",
       "       8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 2385)\n"
     ]
    }
   ],
   "source": [
    "arr = arr.astype(numpy.float32)  # float64 ==> float32\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate of chainer.iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0 0 0 0 0 0 0] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2596c604d2fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mid_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTupleDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerialIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[0 0 0 0 0 0 0] not in index'"
     ]
    }
   ],
   "source": [
    "# 解析データの準備\n",
    "id_train = label[0:50]\n",
    "id_test = label[50:60]\n",
    "\n",
    "train = tuple_dataset.TupleDataset(arr[id_train],id_train.T)\n",
    "train_iter = chainer.iterators.SerialIterator(train, 50)\n",
    "\n",
    "test = tuple_dataset.TupleDataset(arr[id_test], id_test.T)\n",
    "test_iter = chainer.iterators.SerialIterator(test, 10, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(1000, 9)\n",
    "model = L.Classifier(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x1355f67a470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup an optimizer\n",
    "#optimizer = chainer.optimizers.Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08)\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "# help(chainer.optimizers.adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "train_iter.reset()\n",
    "out_directory = \"./Result2018_oono/%s\" % time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# test_iter.reset()\n",
    "\n",
    "# Set up a trainer\n",
    "updater = training.updaters.StandardUpdater(\n",
    "    train_iter, optimizer)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out=out_directory)\n",
    "\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model))\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "# Take a snapshot for each specified epoch\n",
    "# frequency = args.epoch if args.frequency == -1 else max(1, args.frequency)\n",
    "# trainer.extend(extensions.snapshot(), trigger=(frequency, 'epoch'))\n",
    "\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport())\n",
    "\n",
    "# Save two plot images to the result dir\n",
    "# if args_plot and extensions.PlotReport.available():\n",
    "trainer.extend(\n",
    "    extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
    "                          'epoch', file_name='loss.png'))\n",
    "trainer.extend(\n",
    "    extensions.PlotReport(\n",
    "        ['main/accuracy', 'validation/main/accuracy'],\n",
    "        'epoch', file_name='accuracy.png'))\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'main/loss', 'validation/main/loss',\n",
    "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "\n",
    "# Print a progress bar to stdout\n",
    "# trainer.extend(extensions.ProgressBar())\n",
    "\n",
    "# chainer.serializers.load_npz(\"\", trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "1           2.20242     2.20074               0.111111       0.111111                  0.19084       \n",
      "2           2.20074     2.19914               0.111111       0.111111                  0.746339      \n",
      "3           2.19914     2.19756               0.111111       0.111111                  1.07496       \n",
      "4           2.19756     2.196                 0.111111       0.111111                  1.47299       \n",
      "5           2.196       2.19447               0.111111       0.111111                  1.81265       \n",
      "6           2.19448     2.19297               0.111111       0.111111                  2.17654       \n",
      "7           2.19297     2.19148               0.111111       0.111111                  2.48442       \n",
      "8           2.19148     2.19001               0.111111       0.111111                  2.83321       \n",
      "9           2.19001     2.18858               0.111111       0.222222                  3.15974       \n",
      "10          2.18858     2.18717               0.222222       0.222222                  3.5356        \n",
      "11          2.18717     2.18581               0.222222       0.222222                  3.88893       \n",
      "12          2.18581     2.18449               0.222222       0.222222                  4.396         \n",
      "13          2.18449     2.18319               0.222222       0.222222                  4.86186       \n",
      "14          2.18319     2.18191               0.222222       0.222222                  5.31839       \n",
      "15          2.18191     2.18063               0.222222       0.222222                  5.73737       \n",
      "16          2.18063     2.17936               0.222222       0.222222                  6.12493       \n",
      "17          2.17936     2.1781                0.222222       0.222222                  6.48655       \n",
      "18          2.1781      2.17686               0.222222       0.222222                  6.86371       \n",
      "19          2.17686     2.17567               0.222222       0.222222                  7.20461       \n",
      "20          2.17567     2.17451               0.222222       0.222222                  7.55281       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import h5py\n",
    "#net.to_cpu()\n",
    "\n",
    "#chainer.serializers.save_hdf5(\"C:/Users/Owner/Desktop/Result2018_oono/%s/model.hdf5\" % time.strftime(\"%Y%m%d_%H%M%S\"), obj=model)\n",
    "\n",
    "#numpy.save(arr=id_test, file=\"C:/Users/Owner/Desktop/Result2018_oono/%s/test_id.npy\" % time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "#numpy.save(arr=id_train, file=\"C:/Users/Owner/Desktop/Result2018_oono/%s/train_id.npy\"  % time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "#net = model.predictor\n",
    "#cnt = 0\n",
    "#for i in range(33):\n",
    "    #print(\"label: %d, pred: %d [%s]\"% (id_test[i], numpy.argmax(net(arr[i].reshape(1, -1)).data),\n",
    "                                     #id_test[i] == numpy.argmax(net(arr[i].reshape(1, -1)).data)))\n",
    "    #if id_test.T[i] == numpy.argmax(net(arr[i].reshape(1, -1)).data):\n",
    "        #cnt = cnt + 1\n",
    "#print(\"%1.1f [%%]\" % (float(cnt/33*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref: 0, Pred: 0 True\n",
      "Ref: 0, Pred: 0 True\n",
      "Ref: 0, Pred: 0 True\n",
      "Ref: 1, Pred: 0 False\n",
      "Ref: 1, Pred: 0 False\n",
      "Ref: 1, Pred: 0 False\n",
      "Ref: 2, Pred: 0 False\n",
      "Ref: 2, Pred: 0 False\n",
      "Ref: 2, Pred: 0 False\n",
      "Ref: 3, Pred: 0 False\n",
      "Ref: 3, Pred: 0 False\n",
      "Ref: 3, Pred: 0 False\n",
      "Ref: 4, Pred: 0 False\n",
      "Ref: 4, Pred: 0 False\n",
      "Ref: 4, Pred: 0 False\n",
      "Ref: 5, Pred: 0 False\n",
      "Ref: 5, Pred: 0 False\n",
      "Ref: 5, Pred: 0 False\n",
      "Ref: 6, Pred: 0 False\n",
      "Ref: 6, Pred: 0 False\n",
      "Ref: 6, Pred: 0 False\n",
      "Ref: 7, Pred: 7 True\n",
      "Ref: 7, Pred: 7 True\n",
      "Ref: 7, Pred: 7 True\n",
      "Ref: 8, Pred: 7 False\n",
      "Ref: 8, Pred: 7 False\n",
      "Ref: 8, Pred: 7 False\n"
     ]
    }
   ],
   "source": [
    "test_iter.reset()\n",
    "\n",
    "test_batch = test_iter.next()\n",
    "test_spc, test_ref = concat_examples(test_batch)  # Test Dataset\n",
    "for i in range(27):\n",
    "    ref = test_ref[i]\n",
    "    pred = numpy.argmax(net(test_spc[i].reshape(1, -1)).data)\n",
    "    print(\"Ref: %d, Pred: %d %s\" % (ref, pred, ref == pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11.8333px",
    "width": "251.833px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "555.867px",
    "left": "0px",
    "right": "1011px",
    "top": "111.133px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
